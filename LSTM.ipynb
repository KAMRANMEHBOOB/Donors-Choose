{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gScB7PGxfScm",
    "outputId": "6a9772ef-5edf-4448-c32c-b440a5d541ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-17 14:45:43--  https://doc-0k-80-docs.googleusercontent.com/docs/securesc/e2th8t97ida4c7qm0bld5ql54cdmkla7/1njv9622c25go0qn7us7o14ejgtjfph1/1608216300000/06629147635963609455/08403420218720776473/1Lz1IHzyhCoWTsDuaD9Kf7OyoLK4XdFTr?e=download&authuser=0&nonce=srer3d63fautk&user=08403420218720776473&hash=kljfh203r5jtrindcmknadce3u1jvirs\n",
      "Resolving doc-0k-80-docs.googleusercontent.com (doc-0k-80-docs.googleusercontent.com)... 173.194.79.132, 2a00:1450:4013:c05::84\n",
      "Connecting to doc-0k-80-docs.googleusercontent.com (doc-0k-80-docs.googleusercontent.com)|173.194.79.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘preprocessed_data.csv’\n",
      "\n",
      "preprocessed_data.c     [        <=>         ] 118.69M  50.8MB/s    in 2.3s    \n",
      "\n",
      "2020-12-17 14:45:46 (50.8 MB/s) - ‘preprocessed_data.csv’ saved [124454659]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget --header=\"Host: doc-0k-80-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,so;q=0.8\" --header=\"Cookie: AUTH_em2qh84qf50cu7hgm8cc1jk92s9uldlr_nonce=srer3d63fautk\" --header=\"Connection: keep-alive\" \"https://doc-0k-80-docs.googleusercontent.com/docs/securesc/e2th8t97ida4c7qm0bld5ql54cdmkla7/1njv9622c25go0qn7us7o14ejgtjfph1/1608216300000/06629147635963609455/08403420218720776473/1Lz1IHzyhCoWTsDuaD9Kf7OyoLK4XdFTr?e=download&authuser=0&nonce=srer3d63fautk&user=08403420218720776473&hash=kljfh203r5jtrindcmknadce3u1jvirs\" -c -O 'preprocessed_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASPvjm1JfrQm",
    "outputId": "f1e8d263-fb8a-45a5-f7ad-7bd591492d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-17 14:46:16--  https://doc-0o-80-docs.googleusercontent.com/docs/securesc/e2th8t97ida4c7qm0bld5ql54cdmkla7/fq85kkgh0iqtpsgirva5il8r4ht63rif/1608216300000/06629147635963609455/08403420218720776473/1Z6bjXmyCaoEzXYo_tRDwLTsfeA2F3K3j?e=download&authuser=0\n",
      "Resolving doc-0o-80-docs.googleusercontent.com (doc-0o-80-docs.googleusercontent.com)... 173.194.79.132, 2a00:1450:4013:c05::84\n",
      "Connecting to doc-0o-80-docs.googleusercontent.com (doc-0o-80-docs.googleusercontent.com)|173.194.79.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘glove_vectors’\n",
      "\n",
      "glove_vectors           [     <=>            ] 121.60M   127MB/s    in 1.0s    \n",
      "\n",
      "2020-12-17 14:46:18 (127 MB/s) - ‘glove_vectors’ saved [127506004]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget --header=\"Host: doc-0o-80-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,so;q=0.8\" --header=\"Cookie: AUTH_em2qh84qf50cu7hgm8cc1jk92s9uldlr=08403420218720776473|1608216300000|5qfrp4if5mt2pg85lapq14b6vim1a4m8\" --header=\"Connection: keep-alive\" \"https://doc-0o-80-docs.googleusercontent.com/docs/securesc/e2th8t97ida4c7qm0bld5ql54cdmkla7/fq85kkgh0iqtpsgirva5il8r4ht63rif/1608216300000/06629147635963609455/08403420218720776473/1Z6bjXmyCaoEzXYo_tRDwLTsfeA2F3K3j?e=download&authuser=0\" -c -O 'glove_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "id": "yW4xM0Yif90B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.initializers import RandomUniform,he_uniform\n",
    "from keras import optimizers\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lUbeRVyhdjR",
    "outputId": "465fa6a5-a0fe-4db7-eac8-8d9f4ccd6870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 712,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('preprocessed_data.csv')\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "id": "zJFJX4Pihx1D"
   },
   "outputs": [],
   "source": [
    "y= dataset[\"project_is_approved\"]\n",
    "dataset.drop(\"project_is_approved\",axis = 1, inplace = True)\n",
    "X=dataset\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "id": "g-8Bh988jE7u"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Metrics(Callback):    \n",
    "  def __init__(self,trainingdata,validationdata,batch_size = 128):\n",
    "\n",
    "    super(Metrics,self).__init__()\n",
    "    self.x = trainingdata[0]\n",
    "    self.y = trainingdata[1]\n",
    "    self.x_test = validationdata[0]\n",
    "    self.y_test = validationdata[1]\n",
    "    \n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.val_auc = []\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "    val_predict = np.array(self.model.predict(self.x_test)).round()\n",
    "    val_pred = np.array(self.model.predict(self.x_test))\n",
    "    val_targ = self.y_test\n",
    "    _val_auc =roc_auc_score(val_targ, val_pred)\n",
    "    self.val_auc.append(_val_auc)\n",
    "    print(\"Auc: %f \" %(_val_auc))\n",
    "    return    \n",
    "\n",
    "validation_data = (X_cv,y_cv)\n",
    "training_data = (X_train,y_train) \n",
    "metrics = Metrics(training_data,validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "id": "3XrWoQ3wB9w0"
   },
   "outputs": [],
   "source": [
    "def auc1(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "\n",
    "  return tf.py_function(auc1, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkhXtT9tkw7l"
   },
   "source": [
    "Encoding Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "id": "1xFYxmlnkzER"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cIWqtIluCpr",
    "outputId": "37001964-d142-445e-8cfd-b6f193713631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train['essay_tokens'] = tokenizer.texts_to_sequences(X_train['essay'].values)\n",
    "X_cv['essay_tokens'] = tokenizer.texts_to_sequences(X_cv['essay'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "id": "pfpTohmc-LFw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_review_length = 300\n",
    "X_train_pad = sequence.pad_sequences(X_train['essay_tokens'].values, maxlen=max_review_length , padding='post' )\n",
    "\n",
    "X_cv_pad  = sequence.pad_sequences(X_cv['essay_tokens'].values, maxlen=max_review_length , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "id": "Ics-TXdhvBVc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('glove_vectors', 'rb') as f:\n",
    "    glove = pickle.load(f)\n",
    "    glove_words =  set(glove.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "id": "W9UulOUpvvRr"
   },
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "max_vocabulary = len(tokenizer.word_index)\n",
    "embedding_matrix = zeros((max_vocabulary+1, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in glove_words:\n",
    "    embedding_vector = glove[word]\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0LiMXaIwKHn"
   },
   "source": [
    "Encoding Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2zsGMpnwNrU",
    "outputId": "a30ac607-69a5-4c4a-d0ef-2b2356a0bc58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(87398, 1) (87398,)\n",
      "(21850, 1) (21850,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "normalizer.fit(X_train['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
    "\n",
    "X_train_number_norm = normalizer.transform(X_train['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
    "X_cv_number_norm = normalizer.transform(X_cv['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
    "\n",
    "X_train_number_norm = X_train_number_norm.reshape(-1,1)\n",
    "X_cv_number_norm = X_cv_number_norm.reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_number_norm.shape, y_train.shape)\n",
    "print(X_cv_number_norm.shape, y_cv.shape)\n",
    "print(\"=\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ez6UMTbcyvWV",
    "outputId": "736db99b-1207-4177-cef8-6bd56b97a00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(87398, 1) (87398,)\n",
      "(21850, 1) (21850,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "normalizer.fit(X_train['price'].values.reshape(1,-1))\n",
    "\n",
    "X_train_price_norm = normalizer.transform(X_train['price'].values.reshape(1,-1))\n",
    "X_cv_price_norm = normalizer.transform(X_cv['price'].values.reshape(1,-1))\n",
    "\n",
    "X_train_price_norm = X_train_price_norm.reshape(-1,1)\n",
    "X_cv_price_norm = X_cv_price_norm.reshape(-1,1)\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_price_norm.shape, y_train.shape)\n",
    "print(X_cv_price_norm.shape, y_cv.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zv2F7PvCXEHz",
    "outputId": "acbd1ab4-fddf-4c19-9a7d-f73789b3d37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87398, 2) (21850, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train_numeric = np.concatenate([X_train_price_norm,X_train_number_norm],axis=1)\n",
    "X_cv_numeric = np.concatenate([X_cv_price_norm,X_cv_number_norm],axis=1)\n",
    "print(X_train_numeric.shape,X_cv_numeric.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mrqn8fS0zOcc"
   },
   "source": [
    "Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjR9Lmm4zSOk",
    "outputId": "b93a1027-cbc2-49ca-f9b1-9e0234618af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "encode.fit(X_train['school_state'].values)\n",
    "X_train_school_state = encode.transform(X_train['school_state'].values)\n",
    "X_cv_school_state = encode.transform(X_cv['school_state'].values)\n",
    "X_train_school_state_unique = np.unique(X_train_school_state)\n",
    "\n",
    "encoded_size_school = len(X_train_school_state_unique) - len(X_train_school_state_unique)/2\n",
    "encoded_size_school = np.ceil(encoded_size_school)\n",
    "encoded_size_school = int(encoded_size_school)\n",
    "print(encoded_size_school)\n",
    "X_train_school_state_unique = len(X_train_school_state_unique)\n",
    "print(X_train_school_state_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nbxQoF03rIC",
    "outputId": "8f5495e6-8c75-4fa0-dad7-6030dcbc0a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "encode.fit(X_train['teacher_prefix'].values)\n",
    "X_train_teacher = encode.transform(X_train['teacher_prefix'].values)\n",
    "X_cv_teacher = encode.transform(X_cv['teacher_prefix'].values)\n",
    "X_train_teacher_unique = np.unique(X_train_teacher)\n",
    "\n",
    "encoded_teacher = len(X_train_teacher_unique) - len(X_train_teacher_unique)/2\n",
    "encoded_teacher = int(np.ceil(encoded_teacher))\n",
    "print(encoded_teacher)\n",
    "X_train_teacher_unique = len(X_train_teacher_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1SN8Nvj69Rd",
    "outputId": "0c18624e-c5ba-406b-d063-fbeff672ecb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "encode.fit(X_train['project_grade_category'].values)\n",
    "X_train_project = encode.transform(X_train['project_grade_category'].values)\n",
    "X_cv_project = encode.transform(X_cv['project_grade_category'].values)\n",
    "X_train_project_unique = np.unique(X_train_project)\n",
    "\n",
    "encoded_project = len(X_train_project_unique) - len(X_train_project_unique)/2\n",
    "encoded_project = int(np.ceil(encoded_project))\n",
    "print(encoded_project)\n",
    "X_train_project_unique = len(X_train_project_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-cn12a77v3a",
    "outputId": "7bb9d813-32e9-4231-cb22-b5cdd2950834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "encode.fit(X_train['clean_categories'].values)\n",
    "X_train_clean = encode.transform(X_train['clean_categories'].values)\n",
    "\n",
    "X_cv_clean = X_cv['clean_categories'].map(lambda s: '<unknown>' if s not in encode.classes_ else s)\n",
    "encode.classes_ = np.append(encode.classes_, '<unknown>')\n",
    "X_cv_clean= encode.transform(X_cv_clean)\n",
    "\n",
    "X_cv_clean = encode.transform(X_cv['clean_categories'].values)\n",
    "X_train_clean_unique = np.unique(X_train_clean)\n",
    "\n",
    "encoded_clean = len(X_train_clean_unique) - len(X_train_clean_unique)/2\n",
    "encoded_clean = int(np.ceil(encoded_clean))\n",
    "print(encoded_clean)\n",
    "X_train_clean_unique = len(X_train_clean_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eNg2NKvHZwx",
    "outputId": "acdc4332-2e40-4f12-a165-8c6f128bd872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "encode.fit(X_train['clean_subcategories'])\n",
    "X_train_clean_sub = encode.transform(X_train['clean_subcategories'].values)\n",
    "\n",
    "X_cv_clean_sub = X_cv['clean_subcategories'].map(lambda s: '<unknown>' if s not in encode.classes_ else s)\n",
    "encode.classes_ = np.append(encode.classes_, '<unknown>')\n",
    "X_cv_clean_sub = encode.transform(X_cv_clean_sub)\n",
    "\n",
    "X_train_clean_sub_unique = np.unique(X_train_clean_sub)\n",
    "\n",
    "\n",
    "encoded_clean_sub = len(X_train_clean_sub_unique) - len(X_train_clean_sub_unique)/2\n",
    "encoded_clean_sub = int(np.ceil(encoded_clean_sub))\n",
    "print(encoded_clean_sub)\n",
    "X_train_clean_sub_unique = len(X_train_clean_sub_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk5mjVoiQWBS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suv0hoQCQf38"
   },
   "source": [
    "Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "id": "v2ALzK7dQjWh"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Input , Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCXIXGLyQ2Rq",
    "outputId": "9f063d31-f15c-4f44-a0a5-93ad4b5fc6ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_224 (InputLayer)          [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_186 (Embedding)       (None, 300, 300)     15544200    input_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_225 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_226 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_227 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_228 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_229 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 300, 90)      140760      embedding_186[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_187 (Embedding)       (None, 1, 26)        1352        input_225[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_188 (Embedding)       (None, 1, 3)         18          input_226[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_189 (Embedding)       (None, 1, 26)        1352        input_227[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_190 (Embedding)       (None, 1, 198)       78408       input_228[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_191 (Embedding)       (None, 1, 2)         10          input_229[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_230 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_185 (Flatten)           (None, 27000)        0           lstm_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_186 (Flatten)           (None, 26)           0           embedding_187[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_187 (Flatten)           (None, 3)            0           embedding_188[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_188 (Flatten)           (None, 26)           0           embedding_189[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_189 (Flatten)           (None, 198)          0           embedding_190[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_190 (Flatten)           (None, 2)            0           embedding_191[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 482)          1446        input_230[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 27737)        0           flatten_185[0][0]                \n",
      "                                                                 flatten_186[0][0]                \n",
      "                                                                 flatten_187[0][0]                \n",
      "                                                                 flatten_188[0][0]                \n",
      "                                                                 flatten_189[0][0]                \n",
      "                                                                 flatten_190[0][0]                \n",
      "                                                                 dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 200)          5547600     concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 200)          0           dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 100)          20100       dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 100)          0           dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 42)           4242        dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 42)           0           dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            86          dropout_80[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,339,574\n",
      "Trainable params: 21,339,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(300,))\n",
    "X = Embedding(output_dim=300, input_dim = max_vocabulary+1, input_length=300 , weights=[embedding_matrix])(input)\n",
    "lstm_1 = LSTM(90, activation='relu',return_sequences=True)(X)\n",
    "flatten_1 = Flatten()(lstm_1)\n",
    "\n",
    "school = Input(shape=(1,))\n",
    "X_school = Embedding(output_dim = encoded_size_school, input_dim= X_train_school_state_unique+1, input_length=1)(school)\n",
    "flatten_2 = Flatten()(X_school)\n",
    "\n",
    "teacher = Input(shape=(1,))\n",
    "X_teacher = Embedding(output_dim= encoded_teacher , input_dim= X_train_teacher_unique+1, input_length=1)(teacher)\n",
    "flatten_3 = Flatten()(X_teacher)\n",
    "\n",
    "clean = Input(shape=(1,))\n",
    "X_clean = Embedding(output_dim= encoded_clean, input_dim= X_train_clean_unique+1, input_length=1)(clean)\n",
    "flatten_4 = Flatten()(X_clean)\n",
    "\n",
    "clean_sub = Input(shape=(1,))\n",
    "X_clean_sub = Embedding(output_dim= encoded_clean_sub, input_dim= X_train_clean_sub_unique+1, input_length=1)(clean_sub)\n",
    "flatten_5 = Flatten()(X_clean_sub)\n",
    "\n",
    "project = Input(shape=(1,))\n",
    "X_project = Embedding(output_dim= encoded_project, input_dim = X_train_project_unique+1,input_length=1)(project)\n",
    "flatten_6 = Flatten()(X_project)\n",
    "\n",
    "X_numbers = Input(shape=(2,))\n",
    "numeric = Dense(482, activation='relu',kernel_initializer='glorot_normal')(X_numbers)\n",
    "\n",
    "X_concatenate = concatenate([flatten_1 , flatten_2 , flatten_3 ,flatten_4 , flatten_5 , flatten_6 , numeric])\n",
    "\n",
    "model = Dense(200, activation=\"relu\", kernel_initializer=\"glorot_normal\")(X_concatenate)\n",
    "#model = BatchNormalization()(model)\n",
    "model = Dropout(0.4)(model)\n",
    "\n",
    "\n",
    "model = Dense(100,activation=\"relu\",kernel_initializer=\"glorot_normal\")(model)\n",
    "model = Dropout(0.4)(model)\n",
    "\n",
    "model = Dense(42, activation=\"relu\", kernel_initializer=\"glorot_uniform\")(model)\n",
    "#model = BatchNormalization()(model)\n",
    "\n",
    "model = Dropout(0.4)(model)\n",
    "\n",
    "\n",
    "output = Dense(2, activation='sigmoid', name='output')(model)\n",
    "\n",
    "model_ready = Model(inputs = [input,school,teacher,clean,clean_sub,project,X_numbers], outputs = output)\n",
    "print(model_ready.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "id": "Nu4c3aGTuBG1"
   },
   "outputs": [],
   "source": [
    "train_all = [X_train_pad,X_train_school_state,X_train_teacher,X_train_clean,X_train_clean_sub,X_train_project,X_train_numeric]\n",
    "\n",
    "test_all = [X_cv_pad,X_cv_school_state,X_cv_teacher,X_cv_clean, X_cv_clean_sub, X_cv_project, X_cv_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "id": "vFblDQlf0yXY"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train, 2) \n",
    "y_cv = np_utils.to_categorical(y_cv, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "id": "jnJooQxjiB3_"
   },
   "outputs": [],
   "source": [
    "def decrease(epoch, lr):    \n",
    "  if (epoch%3 == 0 and epoch!=0):    \n",
    "    lr = lr - (0.1 * lr)\n",
    "    return lr\n",
    "  else:\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "id": "Soylq79xgJIP"
   },
   "outputs": [],
   "source": [
    "DynamicLR = ReduceLROnPlateau(monitor='val_auroc', factor=0.9, patience=1, verbose=1, mode='max',min_delta=0, cooldown=0, min_lr=0.0001)\n",
    "adaptiveLR =  LearningRateScheduler(decrease)\n",
    "adam = tf.keras.optimizers.Adam(0.001)\n",
    "callbacks_1 = [DynamicLR,adaptiveLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "id": "506AGCgW1ESP"
   },
   "outputs": [],
   "source": [
    "model_ready.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[auroc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaG8i21Q13Vt",
    "outputId": "7ecb6b0b-9007-4398-af6d-8cb911744480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "342/342 [==============================] - 203s 594ms/step - loss: 0.4060 - auroc: 0.6845 - val_loss: 0.3748 - val_auroc: 0.7446\n",
      "Epoch 2/3\n",
      "342/342 [==============================] - 203s 595ms/step - loss: 0.3646 - auroc: 0.7672 - val_loss: 0.3714 - val_auroc: 0.7471\n",
      "Epoch 3/3\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.3190 - auroc: 0.8370\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "342/342 [==============================] - 203s 594ms/step - loss: 0.3190 - auroc: 0.8370 - val_loss: 0.3921 - val_auroc: 0.7278\n"
     ]
    }
   ],
   "source": [
    "history = model_ready.fit(train_all, y_train, batch_size=256, epochs=3, verbose=1,callbacks=callbacks_1, validation_data=(test_all, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trainable Parameters</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Word Embedding</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>21339574</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vectorizer Model  Trainable Parameters    AUC\n",
       "0  Word Embedding  LSTM              21339574  0.728"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pandas.DataFrame({\n",
    "    \"Vectorizer\":['Word Embedding'],\n",
    "    \"Model\":[\"LSTM\"],\n",
    "    \"Trainable Parameters\":[21339574],\n",
    "    \"AUC\":[0.728],\n",
    "    \n",
    "})\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "25_try.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
